{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyP9dHWkxDe8vRZUDppL9oMU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Installing packages"],"metadata":{"id":"ALDFkYLBLMHA"}},{"cell_type":"code","source":["!pip install datasets --quiet\n","!pip install torch --quiet\n","!pip install keras --quiet"],"metadata":{"id":"tfbIETa2LQN9","executionInfo":{"status":"ok","timestamp":1714055356573,"user_tz":-120,"elapsed":16784,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Importing relevant packages"],"metadata":{"id":"BMKuW4YBLrh2"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"0dzMVDvJK9zX","executionInfo":{"status":"ok","timestamp":1714055362283,"user_tz":-120,"elapsed":5713,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.model_selection import StratifiedKFold\n","import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"markdown","source":["Load data for training"],"metadata":{"id":"9d9OQr8mMW4r"}},{"cell_type":"code","source":["np.random.seed(42)  # Set the seed for NumPy random number generation\n","\n","def load_data(base_dir, layer):\n","    embeddings = []\n","    labels = []\n","    label_map = {}\n","    current_label = 0\n","\n","    # Iterate over each speaker's directory\n","    for speaker_dir in os.listdir(base_dir):\n","        # Build the path to the specific layer for the current speaker\n","        layer_dir = os.path.join(base_dir, speaker_dir, layer)\n","\n","        if os.path.isdir(layer_dir):\n","            # Load all .npy files in this layer directory\n","            for file_name in os.listdir(layer_dir):\n","                if file_name.endswith('.npy'):\n","                    path = os.path.join(layer_dir, file_name)\n","                    embedding = np.load(path)\n","                    embeddings.append(embedding)\n","\n","                    # Map speaker to a label if not already done\n","                    if speaker_dir not in label_map:\n","                        label_map[speaker_dir] = current_label\n","                        current_label += 1\n","\n","                    # Append the label for each embedding\n","                    labels.append(label_map[speaker_dir])\n","\n","    # Convert list of embeddings and labels to numpy arrays\n","    embeddings = np.array(embeddings)\n","    labels = np.array(labels)\n","    return embeddings, labels\n"],"metadata":{"id":"lbODOJ8GMEQA","executionInfo":{"status":"ok","timestamp":1714055362283,"user_tz":-120,"elapsed":6,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Creating model"],"metadata":{"id":"-u2FlVSuQa81"}},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=(5, 5), padding=(2, 2))\n","        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=(1, 1))\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1))\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(128 * 12 * 128, 128)  # Adjust the flattened size according to your input shape\n","        self.fc2 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv3(x))\n","        x = self.pool(x)\n","        x = x.view(-1, 128 * 12 * 128)  # Flatten the tensor for the fully connected layer\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n"],"metadata":{"id":"jNt0c7csQZIP","executionInfo":{"status":"ok","timestamp":1714055362284,"user_tz":-120,"elapsed":6,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Function to train und evaluate all layers by iterating over them."],"metadata":{"id":"JQrARRdpZusx"}},{"cell_type":"code","source":["def train_and_evaluate(base_dir, layers, num_classes, device, epochs=30, weight_decay=0.01):\n","    results = []\n","    for layer in layers:\n","        embeddings, labels = load_data(base_dir, layer)\n","\n","        train_dataset = TensorDataset(torch.from_numpy(embeddings), torch.from_numpy(labels))\n","        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","        model = CNN(num_classes=num_classes).to(device)\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=weight_decay)\n","\n","        epoch_data = {'epoch': [], 'train_loss': [], 'train_accuracy': [], 'train_precision': [], 'train_recall': [], 'train_f1': []}\n","\n","        for epoch in range(epochs):\n","            model.train()\n","            total_loss = 0\n","            correct = 0\n","            total = 0\n","            predictions = []\n","            targets_list = []\n","            for inputs, targets in train_loader:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","                loss.backward()\n","                optimizer.step()\n","                total_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs, 1)\n","                correct += (predicted == targets).sum().item()\n","                total += targets.size(0)\n","                predictions.extend(predicted.cpu().numpy())\n","                targets_list.extend(targets.cpu().numpy())\n","\n","            accuracy = correct / total\n","            precision, recall, f1, _ = precision_recall_fscore_support(targets_list, predictions, average='weighted')\n","\n","            epoch_data['epoch'].append(epoch)\n","            epoch_data['train_loss'].append(total_loss / len(train_loader))\n","            epoch_data['train_accuracy'].append(accuracy)\n","            epoch_data['train_precision'].append(precision)\n","            epoch_data['train_recall'].append(recall)\n","            epoch_data['train_f1'].append(f1)\n","\n","            print(f\"Layer: {layer}, Epoch: {epoch+1}, Train Loss: {total_loss / len(train_loader)}, Train Accuracy: {accuracy}, Train Precision: {precision}, Train Recall: {recall}, Train F1: {f1}\")\n","\n","        results.append((layer, total_loss / len(train_loader), accuracy, precision, recall, f1))\n","        df = pd.DataFrame(epoch_data)\n","        df.to_csv(f\"{layer}_training_progress.csv\", index=False)\n","\n","    return results\n"],"metadata":{"id":"qJnbXmf5VLTz","executionInfo":{"status":"ok","timestamp":1714055362284,"user_tz":-120,"elapsed":5,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Saving results and training progress of each step into CSV file."],"metadata":{"id":"GcTa5TYoZ5F0"}},{"cell_type":"code","source":["def save_final_results(results):\n","    df_results = pd.DataFrame(results, columns=['Layer', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n","    df_results.to_csv(\"final_results.csv\", index=False)"],"metadata":{"id":"ieqkuLbPVP9r","executionInfo":{"status":"ok","timestamp":1714055362284,"user_tz":-120,"elapsed":5,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Conducting training and evaluation"],"metadata":{"id":"RhC2J_uhZ8_i"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","base_dir = '/content/drive/My Drive/new_speaker_identification/clips__test/'\n","layers = ['layer_0_processed', 'layer_5_processed', 'layer_10_processed', 'layer_20_processed', 'layer_24_processed']\n","num_classes = 25\n","results = train_and_evaluate(base_dir, layers, num_classes, device)\n","save_final_results(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YY5IIRRUc24","outputId":"b6dcb926-ae84-4a73-9bef-8734f46ffea1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cuda\n","Layer: layer_0_processed, Epoch: 1, Train Loss: 2.374937711510004, Train Accuracy: 0.3174038402551991, Train Precision: 0.343989696899871, Train Recall: 0.3174038402551991, Train F1: 0.31022669044002393\n","Layer: layer_0_processed, Epoch: 2, Train Loss: 1.0196667647829243, Train Accuracy: 0.6275688608060855, Train Precision: 0.6236216139843251, Train Recall: 0.6275688608060855, Train F1: 0.6219724458391239\n","Layer: layer_0_processed, Epoch: 3, Train Loss: 0.8568880525289797, Train Accuracy: 0.6777498312986934, Train Precision: 0.6769571779478768, Train Recall: 0.6777498312986934, Train F1: 0.6746172457635058\n","Layer: layer_0_processed, Epoch: 4, Train Loss: 0.7408432809745564, Train Accuracy: 0.7136372001717686, Train Precision: 0.7140360358928579, Train Recall: 0.7136372001717686, Train F1: 0.7109003675893407\n","Layer: layer_0_processed, Epoch: 5, Train Loss: 0.7008430404990327, Train Accuracy: 0.721612171032452, Train Precision: 0.7236100690841214, Train Recall: 0.721612171032452, Train F1: 0.7200852628797635\n","Layer: layer_0_processed, Epoch: 6, Train Loss: 0.6387636056133345, Train Accuracy: 0.7439420894423655, Train Precision: 0.7476245318668215, Train Recall: 0.7439420894423655, Train F1: 0.7421499217666189\n","Layer: layer_0_processed, Epoch: 7, Train Loss: 0.5908244528022467, Train Accuracy: 0.7606281823201031, Train Precision: 0.7649177268184338, Train Recall: 0.7606281823201031, Train F1: 0.7589681455201023\n","Layer: layer_0_processed, Epoch: 8, Train Loss: 0.5482322586517708, Train Accuracy: 0.775719281025704, Train Precision: 0.7784845885884709, Train Recall: 0.775719281025704, Train F1: 0.7745221204615205\n","Layer: layer_0_processed, Epoch: 9, Train Loss: 0.5285919046869465, Train Accuracy: 0.7861480890742899, Train Precision: 0.7892500600856442, Train Recall: 0.7861480890742899, Train F1: 0.7840760750533764\n","Layer: layer_0_processed, Epoch: 10, Train Loss: 0.5052630363726148, Train Accuracy: 0.7900128826452365, Train Precision: 0.793863763626691, Train Recall: 0.7900128826452365, Train F1: 0.7881567968737506\n","Layer: layer_0_processed, Epoch: 11, Train Loss: 0.5017310577864741, Train Accuracy: 0.7935096006379977, Train Precision: 0.7962201456586815, Train Recall: 0.7935096006379977, Train F1: 0.7922603160334256\n","Layer: layer_0_processed, Epoch: 12, Train Loss: 0.4909318193501117, Train Accuracy: 0.7938776762161831, Train Precision: 0.7979631579311858, Train Recall: 0.7938776762161831, Train F1: 0.7932080735285723\n","Layer: layer_0_processed, Epoch: 13, Train Loss: 0.47996301826308757, Train Accuracy: 0.8029568738114227, Train Precision: 0.8071619954263537, Train Recall: 0.8029568738114227, Train F1: 0.802283311301263\n","Layer: layer_0_processed, Epoch: 14, Train Loss: 0.4471714348185296, Train Accuracy: 0.8127722225630329, Train Precision: 0.8169233635707699, Train Recall: 0.8127722225630329, Train F1: 0.8119840002130514\n","Layer: layer_0_processed, Epoch: 15, Train Loss: 0.4548687292664659, Train Accuracy: 0.8132629900006134, Train Precision: 0.8191247633568283, Train Recall: 0.8132629900006134, Train F1: 0.8122105615279243\n","Layer: layer_0_processed, Epoch: 16, Train Loss: 0.4302779853928323, Train Accuracy: 0.8202564259861358, Train Precision: 0.8250626166859604, Train Recall: 0.8202564259861358, Train F1: 0.8194167569877416\n","Layer: layer_0_processed, Epoch: 17, Train Loss: 0.4336492986655703, Train Accuracy: 0.819949696337648, Train Precision: 0.8254975622829607, Train Recall: 0.819949696337648, Train F1: 0.8196364741396124\n","Layer: layer_0_processed, Epoch: 18, Train Loss: 0.4232954511455461, Train Accuracy: 0.827986013128029, Train Precision: 0.832823733575916, Train Recall: 0.827986013128029, Train F1: 0.8279179596607817\n","Layer: layer_0_processed, Epoch: 19, Train Loss: 0.4069556323920979, Train Accuracy: 0.8340592601680878, Train Precision: 0.8382175781663893, Train Recall: 0.8340592601680878, Train F1: 0.8337284015763907\n"]}]}]}