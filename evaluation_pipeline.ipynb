{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyNWjNHJ/8iLHxwkWxZuYoqk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Installing packages"],"metadata":{"id":"ALDFkYLBLMHA"}},{"cell_type":"code","source":["!pip install datasets --quiet\n","!pip install torch --quiet\n","!pip install keras --quiet"],"metadata":{"id":"tfbIETa2LQN9","executionInfo":{"status":"ok","timestamp":1714235123066,"user_tz":-120,"elapsed":14797,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Importing relevant packages"],"metadata":{"id":"BMKuW4YBLrh2"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"0dzMVDvJK9zX","executionInfo":{"status":"ok","timestamp":1714235128088,"user_tz":-120,"elapsed":5027,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.model_selection import StratifiedKFold\n","import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"markdown","source":["Load data for training"],"metadata":{"id":"9d9OQr8mMW4r"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import re\n","\n","def load_data(base_dir, layer):\n","    embeddings = []\n","    labels = []\n","    label_map = {}\n","\n","    # Iterate over each speaker's directory\n","    for speaker_dir in os.listdir(base_dir):\n","        # Extract the speaker number from the directory name\n","        match = re.search(r'(\\d+)', speaker_dir)\n","        if match:\n","            # Subtract 1 to shift labels from [1, 25] to [0, 24]\n","            label = int(match.group(1)) - 1\n","\n","            # Build the path to the specific layer for the current speaker\n","            layer_dir = os.path.join(base_dir, speaker_dir, layer)\n","\n","            if os.path.isdir(layer_dir) and 'no_overlap' in layer_dir:\n","                # Load all .npy files in this layer directory\n","                for file_name in os.listdir(layer_dir):\n","                    if file_name.endswith('.npy'):\n","                        path = os.path.join(layer_dir, file_name)\n","                        embedding = np.load(path)\n","                        embeddings.append(embedding)\n","\n","                        # Append the label for each embedding\n","                        labels.append(label)\n","\n","    # Convert list of embeddings and labels to numpy arrays\n","    embeddings = np.array(embeddings)\n","    labels = np.array(labels)\n","    return embeddings, labels"],"metadata":{"id":"lbODOJ8GMEQA","executionInfo":{"status":"ok","timestamp":1714235128089,"user_tz":-120,"elapsed":11,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Creating model"],"metadata":{"id":"-u2FlVSuQa81"}},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=(5, 5), padding=(2, 2))\n","        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=(1, 1))\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1))\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(128 * 12 * 128, 128)  # Adjust the flattened size according to your input shape\n","        self.fc2 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv3(x))\n","        x = self.pool(x)\n","        x = x.view(-1, 128 * 12 * 128)  # Flatten the tensor for the fully connected layer\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n"],"metadata":{"id":"jNt0c7csQZIP","executionInfo":{"status":"ok","timestamp":1714235128089,"user_tz":-120,"elapsed":9,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Function to train und evaluate all layers by iterating over them."],"metadata":{"id":"JQrARRdpZusx"}},{"cell_type":"code","source":["def evaluate_model(model, loader, device, male_indices, female_indices):\n","    y_true = []\n","    y_pred = []\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, targets in loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            y_pred.extend(predicted.cpu().numpy())\n","            y_true.extend(targets.cpu().numpy())\n","\n","    # Berechnung der Gesamtmetriken\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n","\n","    # Berechnung der Metriken für männliche Sprecher\n","    male_mask = np.isin(y_true, male_indices)\n","    male_accuracy = accuracy_score(np.array(y_true)[male_mask], np.array(y_pred)[male_mask])\n","    male_precision, male_recall, male_f1, _ = precision_recall_fscore_support(np.array(y_true)[male_mask], np.array(y_pred)[male_mask], average='weighted')\n","\n","    # Berechnung der Metriken für weibliche Sprecher\n","    female_mask = np.isin(y_true, female_indices)\n","    female_accuracy = accuracy_score(np.array(y_true)[female_mask], np.array(y_pred)[female_mask])\n","    female_precision, female_recall, female_f1, _ = precision_recall_fscore_support(np.array(y_true)[female_mask], np.array(y_pred)[female_mask], average='weighted')\n","\n","    return {\n","        'total': (accuracy, precision, recall, f1),\n","        'male': (male_accuracy, male_precision, male_recall, male_f1),\n","        'female': (female_accuracy, female_precision, female_recall, female_f1)\n","    }\n"],"metadata":{"id":"71GcdTtr0ZwP","executionInfo":{"status":"ok","timestamp":1714235128089,"user_tz":-120,"elapsed":9,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def train_and_evaluate(base_dir, layers, num_classes, male_indices, female_indices, device, epochs=30, weight_decay=0.01, test_size=0.2):\n","    torch.manual_seed(0)  # Setzen des Seeds für reproduzierbare Ergebnisse\n","    results = []\n","    for layer in layers:\n","        # Daten laden\n","        embeddings, labels = load_data(base_dir, layer)\n","\n","        # Aufteilen in Trainings- und Testdatensätze\n","        X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=test_size, random_state=0)\n","\n","        # Trainingsdatensatz vorbereiten\n","        train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n","        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","        # Testdatensatz vorbereiten\n","        test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n","        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","        # Modell initialisieren\n","        model = CNN(num_classes=num_classes).to(device)\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=weight_decay)\n","\n","        epoch_data = {'epoch': [], 'train_loss': [], 'train_accuracy': []}\n","\n","        for epoch in range(epochs):\n","            model.train()\n","            total_loss = 0\n","            correct = 0\n","            total = 0\n","            for inputs, targets in train_loader:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","                loss.backward()\n","                optimizer.step()\n","                total_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs, 1)\n","                correct += (predicted == targets).sum().item()\n","                total += targets.size(0)\n","\n","            # Trainingsgenauigkeit berechnen\n","            train_accuracy = correct / total\n","\n","            # Speichern der Trainingsmetriken\n","            epoch_data['epoch'].append(epoch)\n","            epoch_data['train_loss'].append(total_loss / len(train_loader))\n","            epoch_data['train_accuracy'].append(train_accuracy)\n","\n","            print(f\"Layer: {layer}, Epoch: {epoch+1}, Train Loss: {total_loss / len(train_loader)}, Train Accuracy: {train_accuracy}\")\n","\n","        # Evaluation auf dem Testdatensatz am Ende des Trainings\n","        test_metrics = evaluate_model(model, test_loader, device, male_indices, female_indices)\n","        print(f\"Test Metrics: Total - {test_metrics['total']}, Male - {test_metrics['male']}, Female - {test_metrics['female']}\")\n","        results.append((layer, epoch_data['train_loss'][-1], epoch_data['train_accuracy'][-1], test_metrics))\n","\n","        # CSV-Datei mit den Trainingsergebnissen speichern\n","        df = pd.DataFrame(epoch_data)\n","        df.to_csv(f\"/content/drive/My Drive/new_speaker_identification/evaluation/{layer}_training_progress.csv\", index=False)\n","\n","    return results"],"metadata":{"id":"qJnbXmf5VLTz","executionInfo":{"status":"ok","timestamp":1714235128089,"user_tz":-120,"elapsed":8,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Saving results and training progress of each step into CSV file."],"metadata":{"id":"GcTa5TYoZ5F0"}},{"cell_type":"code","source":["def save_final_results(results, save_path):\n","    # Vorbereiten einer Liste für den DataFrame\n","    expanded_results = []\n","    for layer, train_loss, train_accuracy, test_metrics in results:\n","        expanded_results.append({\n","            'Layer': layer,\n","            'Train Loss': train_loss,\n","            'Train Accuracy': train_accuracy,\n","            'Test Accuracy Total': test_metrics['total'][0],\n","            'Test Precision Total': test_metrics['total'][1],\n","            'Test Recall Total': test_metrics['total'][2],\n","            'Test F1-Score Total': test_metrics['total'][3],\n","            'Test Accuracy Male': test_metrics['male'][0],\n","            'Test Precision Male': test_metrics['male'][1],\n","            'Test Recall Male': test_metrics['male'][2],\n","            'Test F1-Score Male': test_metrics['male'][3],\n","            'Test Accuracy Female': test_metrics['female'][0],\n","            'Test Precision Female': test_metrics['female'][1],\n","            'Test Recall Female': test_metrics['female'][2],\n","            'Test F1-Score Female': test_metrics['female'][3]\n","        })\n","\n","    # Erstellen des DataFrame\n","    df_results = pd.DataFrame(expanded_results)\n","    df_results.to_csv(save_path, index=False)"],"metadata":{"id":"ieqkuLbPVP9r","executionInfo":{"status":"ok","timestamp":1714235128089,"user_tz":-120,"elapsed":8,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Conducting training and evaluation"],"metadata":{"id":"RhC2J_uhZ8_i"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Definition der Indizes für männliche und weibliche Sprecher\n","# male_indices = [15, 21, 24, 8, 23, 25, 22, 5, 10, 9]\n","# female_indices = [17, 16, 14, 13, 12, 11, 7, 6, 4, 3, 2, 1]\n","\n","male_indices = [20, 19, 15, 21, 24, 8, 23, 25, 22, 5, 10, 9]\n","female_indices = [18, 17, 16, 14, 13, 12, 11, 7, 6, 4, 3, 2, 1]\n","\n","# Reduzieren Sie jeden Index um 1, um den Bereich von 0 bis 24 zu erhalten\n","male_indices = [i - 1 for i in male_indices]\n","female_indices = [i - 1 for i in female_indices]\n","\n","base_dir = '/content/drive/My Drive/new_speaker_identification/clips__test/'\n","layers = ['layer_0_no_overlap', 'layer_5_no_overlap', 'layer_10_no_overlap', 'layer_15_no_overlap', 'layer_20_no_overlap', 'layer_24_no_overlap']\n","num_classes = 25\n","results = train_and_evaluate(base_dir=base_dir, layers=layers, num_classes=num_classes, device=device, male_indices=male_indices, female_indices=female_indices)\n","save_final_results(results, '/content/drive/My Drive/new_speaker_identification/evaluation/final_results.csv')"],"metadata":{"id":"1YY5IIRRUc24"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Logistic regression\n","\n","Now trying to reproduce the trends with a way simpler model, using logistic regression."],"metadata":{"id":"czhxQtATvzKp"}},{"cell_type":"markdown","source":["first we need to flatten the input matrices, because logistic regression is not able to process matrices."],"metadata":{"id":"lnPAUWfcwelB"}},{"cell_type":"code","source":["def load_data(base_dir, layer):\n","    embeddings = []\n","    labels = []\n","\n","    # Iterate over each speaker's directory\n","    for speaker_dir in os.listdir(base_dir):\n","        # Extract the speaker number from the directory name\n","        match = re.search(r'(\\d+)', speaker_dir)\n","        if match:\n","            # Subtract 1 to shift labels from [1, 25] to [0, 24]\n","            label = int(match.group(1)) - 1\n","\n","            # Build the path to the specific layer for the current speaker\n","            layer_dir = os.path.join(base_dir, speaker_dir, layer)\n","\n","            if os.path.isdir(layer_dir) and 'no_overlap' in layer_dir:\n","                # Load all .npy files in this layer directory\n","                for file_name in os.listdir(layer_dir):\n","                    if file_name.endswith('.npy'):\n","                        path = os.path.join(layer_dir, file_name)\n","                        embedding = np.load(path)\n","\n","                        # Flatten the embedding to a 1D array if it's not already\n","                        embedding = embedding.flatten()\n","                        embeddings.append(embedding)\n","\n","                        # Append the label for each embedding\n","                        labels.append(label)\n","\n","    # Convert list of embeddings and labels to numpy arrays\n","    embeddings = np.array(embeddings)\n","    labels = np.array(labels)\n","    return embeddings, labels\n"],"metadata":{"id":"PLE6kR39wdxu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now implementing the logistic regression training and evaluation."],"metadata":{"id":"jHAimF2Mwv_I"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","def train_and_evaluate(base_dir, layers, num_classes, male_indices, female_indices, epochs=30, test_size=0.2):\n","    results = []\n","    for layer in layers:\n","        # Daten laden (dies muss die Daten als 2D-Featurematrix zurückgeben)\n","        embeddings, labels = load_data(base_dir, layer)\n","\n","        # Aufteilen in Trainings- und Testdatensätze\n","        X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=test_size, random_state=0)\n","\n","        # Modell initialisieren (Logistische Regression)\n","        model = LogisticRegression(max_iter=epochs)\n","\n","        # Modell trainieren\n","        model.fit(X_train, y_train)\n","\n","        # Evaluation auf dem Testdatensatz am Ende des Trainings\n","        test_metrics = evaluate_model(model, X_test, y_test, male_indices, female_indices)\n","        print(f\"Layer: {layer}, Test Metrics: {test_metrics}\")\n","\n","        # Ergebnisse speichern\n","        results.append((layer, test_metrics))\n","\n","        # CSV-Datei mit den Trainingsergebnissen speichern\n","        df = pd.DataFrame(test_metrics)\n","        df.to_csv(f\"/content/drive/My Drive/new_speaker_identification/evaluation/{layer}_training_progress.csv\", index=False)\n","\n","    return results\n","\n","def evaluate_model(model, X_test, y_test, male_indices, female_indices):\n","    # Vorhersagen machen\n","    y_pred = model.predict(X_test)\n","    # Gesamtmetriken\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n","\n","    # Metriken für männliche Sprecher\n","    male_mask = np.isin(y_test, male_indices)\n","    male_accuracy = accuracy_score(y_test[male_mask], y_pred[male_mask])\n","    male_precision, male_recall, male_f1, _ = precision_recall_fscore_support(y_test[male_mask], y_pred[male_mask], average='weighted')\n","\n","    # Metriken für weibliche Sprecher\n","    female_mask = np.isin(y_test, female_indices)\n","    female_accuracy = accuracy_score(y_test[female_mask], y_pred[female_mask])\n","    female_precision, female_recall, female_f1, _ = precision_recall_fscore_support(y_test[female_mask], y_pred[female_mask], average='weighted')\n","\n","    return {\n","        'total': {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1},\n","        'male': {'accuracy': male_accuracy, 'precision': male_precision, 'recall': male_recall, 'f1': male_f1},\n","        'female': {'accuracy': female_accuracy, 'precision': female_precision, 'recall': female_recall, 'f1': female_f1}\n","    }\n","\n","# Anpassen der Datenladefunktion und anderer benötigter Komponenten entsprechend"],"metadata":{"id":"v9DlAB4TvyNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_final_results(results, save_path):\n","    # Vorbereiten einer Liste für den DataFrame\n","    expanded_results = []\n","    for layer, metrics in results:\n","        expanded_results.append({\n","            'Layer': layer,\n","            'Test Accuracy Total': metrics['total']['accuracy'],\n","            'Test Precision Total': metrics['total']['precision'],\n","            'Test Recall Total': metrics['total']['recall'],\n","            'Test F1-Score Total': metrics['total']['f1'],\n","            'Test Accuracy Male': metrics['male']['accuracy'],\n","            'Test Precision Male': metrics['male']['precision'],\n","            'Test Recall Male': metrics['male']['recall'],\n","            'Test F1-Score Male': metrics['male']['f1'],\n","            'Test Accuracy Female': metrics['female']['accuracy'],\n","            'Test Precision Female': metrics['female']['precision'],\n","            'Test Recall Female': metrics['female']['recall'],\n","            'Test F1-Score Female': metrics['female']['f1']\n","        })\n","\n","    # Erstellen des DataFrame\n","    df_results = pd.DataFrame(expanded_results)\n","    df_results.to_csv(save_path, index=False)"],"metadata":{"id":"DsuTPPBlzAl8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hier startet der Aufruf\n","results = train_and_evaluate(\n","    base_dir='/content/drive/My Drive/new_speaker_identification/clips__test/',\n","    layers=[\n","        'layer_0_no_overlap', 'layer_5_no_overlap', 'layer_10_no_overlap',\n","        'layer_15_no_overlap', 'layer_20_no_overlap', 'layer_24_no_overlap'\n","    ],\n","    num_classes=25,\n","    male_indices=[i - 1 for i in [20, 19, 15, 21, 24, 8, 23, 25, 22, 5, 10, 9]],  # Indizes angepasst\n","    female_indices=[i - 1 for i in [18, 17, 16, 14, 13, 12, 11, 7, 6, 4, 3, 2, 1]],  # Indizes angepasst\n","    epochs=100,\n","    test_size=0.2\n",")\n","\n","# Speichern der Resultate\n","save_final_results(\n","    results,\n","    '/content/drive/My Drive/new_speaker_identification/evaluation/final_results.csv'\n",")"],"metadata":{"id":"uwmFXbvRy5Fh"},"execution_count":null,"outputs":[]}]}