{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMtbMLm4Y3V9MTHvaYTdeMI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import librosa\n","import torch\n","from transformers import Wav2Vec2Processor, Wav2Vec2Model"],"metadata":{"id":"ZbaSGqT6PzvE","executionInfo":{"status":"ok","timestamp":1713186391719,"user_tz":-120,"elapsed":8501,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from transformers import Wav2Vec2Model\n","\n","# Laden des Modells\n","model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-xls-r-300m\")\n","\n","# Anzahl der Transformer-Schichten im Modell\n","num_layers = model.config.num_hidden_layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZY-biAqRf55","executionInfo":{"status":"ok","timestamp":1713186438623,"user_tz":-120,"elapsed":3551,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}},"outputId":"da7f5c19-fead-474a-dba0-ebf61013d28c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","\n","# Setzen Sie den Pfad zu dem Verzeichnis, das Ihre MP3-Dateien enthält\n","directory_path = '/content/drive/My Drive/NLP/clips__test'\n","\n","print(len(os.listdir(directory_path)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umZPI89LQB1y","executionInfo":{"status":"ok","timestamp":1713186460434,"user_tz":-120,"elapsed":21818,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}},"outputId":"da1d7730-6de9-4bc1-b9e9-231079200e92"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","20\n"]}]},{"cell_type":"code","source":["os.listdir(directory_path)[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PuArxi8QTTkg","executionInfo":{"status":"ok","timestamp":1713186464676,"user_tz":-120,"elapsed":461,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}},"outputId":"aa498178-307c-4f59-fb0a-b1c8b9482d80"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['gut_acf67674-c912-42c0-ba3c-f85e2db965ac',\n"," 'gut_4ee1811c-9884-4261-99cb-2f7346c8ea6e',\n"," 'gut_684dd9cf-2844-407b-9a7f-12e7b559773f',\n"," 'gut_005039b8-898f-48d8-b7cc-8a16bd1055c8',\n"," 'gut_86c0e008-eebd-44ab-ac69-23706252a2e5',\n"," 'gut_8b48025a-2cff-4346-9dab-b45cfb683e22',\n"," 'gut_31cab952-98eb-45cb-a243-c951519c5c40',\n"," 'gut_0d54807c-ec46-415f-8ef2-0a2f769aab1a',\n"," 'gut_8050767b-0a0e-43db-8754-2a42e896f7dd',\n"," 'gut_d9be733d-d0bd-41bb-8dc5-dfcabb99c105']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L15GvisEPtQl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8357ce04-67eb-49e4-af96-e6c6a1a8fda2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 364/364 [01:14<00:00,  4.89it/s]\n","  1%|          | 3/362 [00:02<04:11,  1.43it/s]"]}],"source":["import os\n","import librosa\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n","\n","# Gerät festlegen, GPU wenn verfügbar, sonst CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-xls-r-300m\")\n","model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-xls-r-300m\", output_hidden_states=True)\n","model.to(device)  # Modell auf das festgelegte Gerät verschieben\n","\n","def load_audio_files(directory, layer_indices=[-1]):\n","    \"\"\"Lädt alle MP3-Dateien im angegebenen Verzeichnis und extrahiert die Repräsentationen aus den spezifizierten Schichten.\"\"\"\n","    for filename in tqdm(os.listdir(directory)):\n","        if filename.endswith(\".mp3\"):\n","            file_path = os.path.join(directory, filename)\n","            audio, sr = librosa.load(file_path, sr=16000)\n","            input_values = feature_extractor(audio, return_tensors=\"pt\", sampling_rate=sr).input_values\n","            input_values = input_values.to(device)  # Eingabedaten auf das Gerät verschieben\n","            with torch.no_grad():\n","                outputs = model(input_values)\n","                for index in layer_indices:\n","                    hidden_states = outputs.hidden_states[index]\n","                    # Erstellt einen Unterordner im selben Verzeichnis für jede Schicht, falls nicht vorhanden\n","                    layer_dir = os.path.join(directory, f\"layer_{index}\")\n","                    os.makedirs(layer_dir, exist_ok=True)\n","                    save_path = os.path.join(layer_dir, f\"{os.path.splitext(filename)[0]}_layer_{index}.npy\")\n","                    np.save(save_path, hidden_states.cpu().numpy())\n","                    # print(f\"Verarbeitet und gespeichert: {filename} in {save_path}\")\n","\n","\n","\n","for d in os.listdir(directory_path):\n","  dir = os.path.join(directory_path, d)\n","  load_audio_files(dir, layer_indices=[0, 5, 10, 15, 20, 24])"]}]}